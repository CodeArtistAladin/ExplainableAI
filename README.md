# ExplainableAI
This project uses a ResNet18 image classifier with LIME to provide explainable AI insights. The Streamlit app lets users upload images, view predictions, and see highlighted regions that influenced the modelâ€™s decision. Built with Python, PyTorch, LIME, and Streamlit to make deep learning more transparent.

ğŸ§  Explainable AI Image Classifier

A simple and interactive Explainable AI (XAI) demo using ResNet18, LIME, and Streamlit.
This project classifies images and highlights the regions that influenced the modelâ€™s decision, making deep learning more transparent and interpretable.

ğŸš€ Features

ğŸ–¼ï¸ Image Upload & Classification
Upload an image and get predictions using a trained ResNet18 model.

ğŸ” LIME Explanation
Generates superpixel-based explanations showing why the model predicted a class.

âš¡ Fast & Lightweight UI
Built with Streamlit for easy local deployment and demonstration.

ğŸ“¦ Modular Codebase
Separate modules for inference, explanation, and app UI.

ğŸ› ï¸ Technologies Used

Python 3.10

PyTorch â€“ model loading & inference

Torchvision â€“ preprocessing & transforms

LIME â€“ explainability

Streamlit â€“ UI

Pillow / NumPy / Matplotlib â€“ image handling & visualization

ğŸ“ Project Structure
explainable-ai-demo/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py            # Streamlit UI
â”‚   â”œâ”€â”€ predict.py        # Model prediction logic
â”‚   â”œâ”€â”€ explain.py        # LIME explanation code
â”‚   â”œâ”€â”€ model.pth         # Trained ResNet18 model
â”‚   â”œâ”€â”€ classes.txt       # Class labels
â”‚   â”œâ”€â”€ utils.py          # Helper functions
â”‚
â””â”€â”€ README.md

â–¶ï¸ How to Run the App

Create & activate virtual environment

python -m venv .venv
.venv\Scripts\activate


Install dependencies

pip install -r requirements.txt


Run the app

streamlit run app.py


Open the browser at
http://localhost:8501

ğŸ“˜ How It Works

The uploaded image is preprocessed and passed into a ResNet18 classifier.

The predicted class is displayed with confidence.

LIME generates an interpretable explanation by:

Segmenting the image into superpixels

Testing how each region affects prediction

Highlighting the regions most responsible

This improves transparency for deep learning systems.

ğŸ¯ Purpose

This project demonstrates how explainable AI can increase trust and interpretability in computer vision models. Ideal for academic presentations, demos, or learning XAI concepts.

Author: 
MD MONEM SHAHREER SURJO
